---
title: "p8105_hw6_dcm2192"
author: "Dylan Morgan"
date: "2024-12-02"
output: github_document
---

Load packages.
```{r setup, message = FALSE}
library(tidyverse)
library(modelr)
library(mgcv)
```

## Problem 2

Load data. 
```{r}
homicide_data <- read_csv("./data/homicide-data.csv")
```

Create city_state variable and homicide solved binary variable. 
Remove cities with missing or inaccurate data. 
Limit victim_race data to black or white, and make victim_age numeric.
```{r}
homicide_data <-
  homicide_data |>
  mutate(
    city_state = str_c(city, ", ", state), 
    solved = as.numeric(disposition == "Closed by arrest"), 
    victim_age = as.numeric(victim_age)
  ) |> 
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")), 
         victim_race %in% c("White", "Black")
         )
```

For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors. Save the output of glm as an R object; apply the broom::tidy to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.

Create Baltimore dataset.
```{r}
baltimore_homicide_data <- 
  homicide_data |> 
  filter(city_state == "Baltimore, MD")
```

Fit logistic regression to Baltimore homicide data. 
Present estimate and CI of OR for solving homicides comparing male victims to female victims, with all other variables fixed. 
```{r}
baltimore_fit_log <- 
  baltimore_homicide_data |> 
  glm(solved ~ victim_age + victim_sex + victim_race, data = _, family = binomial())

baltimore_fit_log |>
  broom::tidy() |>
  mutate(OR = exp(estimate), 
         CI_lower = confint(baltimore_fit_log)[,1], 
         CI_upper = confint(baltimore_fit_log)[,2]) |>
  select(term, log_OR = estimate, OR, CI_lower, CI_upper, p.value) |>
  knitr::kable(digits = 3)
```

Run models for each city.
```{r}
nest_glm_cities_results <- 
  homicide_data |> 
  nest(data = -city_state) |> 
  mutate(
    models = map(data, \(df) glm(solved ~ victim_age + victim_sex + victim_race, data = df)), 
    results = map(models, broom::tidy)) |> 
  unnest(results)

confint(glm(solved ~ victim_age + victim_sex + victim_race, data = homicide_data))

nest_glm_cities_results |> 
  select(city_state, term, estimate) |> 
  mutate(term = fct_inorder(term)) |> 
  pivot_wider(
    names_from = term, values_from = estimate) |> 
  knitr::kable(digits = 3)
```

## Problem 3

Load dataset.
```{r}
birthweight <- read_csv("./data/birthweight.csv")

birthweight <- 
  birthweight |> 
  mutate(babysex = as.factor(babysex), 
         frace = as.factor(frace), 
         malform = as.factor(malform), 
         mrace = as.factor(mrace)) |> 
  select(-c(pnumlbw, pnumsga))
```

Propose regression model.
```{r}
bwt_fit_log <- 
  birthweight |> 
  glm(bwt~., data = _)

best_mod_proposal <- MASS::stepAIC(bwt_fit_log, trace=FALSE)

best_mod_proposal |>
  broom::tidy() |>
  mutate(OR = exp(estimate)) |>
  select(term, log_OR = estimate, OR, p.value) |>
  knitr::kable(digits = 3)

birthweight |> 
  modelr::add_residuals(best_mod_proposal) |> 
  modelr::add_predictions(best_mod_proposal) |> 
  ggplot(aes(x = pred, y = resid)) + geom_violin()
```

Using the `stepAIC` function learned from a previous class, I was able to produce a reasonable model by allowing the `stepAIC` function to remove the factors calculated to not be as significant as the factors that remained in the model. The majority of the remaining variables had p-values less than 0.05, making them statistically significant.

Compare with two other models.
```{r}
bwt_fit_gest_age <- 
  birthweight |> 
  glm(bwt ~ blength + gaweeks, data = _)

bwt_fit_bhead <- 
  birthweight |> 
  glm(bwt ~ bhead + blength + babysex + 
        bhead*blength + 
        bhead*babysex + 
        blength*babysex + 
        bhead*blength*babysex, 
      data = _)
```

Cross-validation. 
```{r}
cv_df <- 
  crossv_mc(birthweight, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df <- 
  cv_df |> 
  mutate(
    main_mod = map(train, \(df) glm(formula = bwt ~ babysex + bhead + blength + delwt + fincome + 
                                       gaweeks + mheight + mrace + parity + ppwt + smoken, data = df)),
    gest_age_mod = map(train, \(df) glm(bwt ~ blength + gaweeks, data = df)),
    bhead_mod = map(train, \(df) glm(bwt ~ bhead + blength + babysex + 
                                         bhead*blength + 
                                         bhead*babysex + 
                                         blength*babysex + 
                                         bhead*blength*babysex, data = df))) |> 
  mutate(
    rmse_main = map2_dbl(main_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_gest_age    = map2_dbl(gest_age_mod, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_bhead = map2_dbl(bhead_mod, test, \(mod, df) rmse(model = mod, data = df)))

cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

